{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "92bG39Uq0Asu",
        "outputId": "6ecd3334-4518-4a8e-b07a-05980dc73eda"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fri Jul 18 09:04:33 2025       \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 550.54.15              Driver Version: 550.54.15      CUDA Version: 12.4     |\n",
            "|-----------------------------------------+------------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id          Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |           Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                        |               MIG M. |\n",
            "|=========================================+========================+======================|\n",
            "|   0  Tesla T4                       Off |   00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P8             10W /   70W |       0MiB /  15360MiB |      0%      Default |\n",
            "|                                         |                        |                  N/A |\n",
            "+-----------------------------------------+------------------------+----------------------+\n",
            "                                                                                         \n",
            "+-----------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                              |\n",
            "|  GPU   GI   CI        PID   Type   Process name                              GPU Memory |\n",
            "|        ID   ID                                                               Usage      |\n",
            "|=========================================================================================|\n",
            "|  No running processes found                                                             |\n",
            "+-----------------------------------------------------------------------------------------+\n"
          ]
        }
      ],
      "source": [
        "# This code cell was written for Google Colab\n",
        "'''!nvidia-smi'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "F1JQEKVC0DyO"
      },
      "outputs": [],
      "source": [
        "# This code cell was written for Google Colab\n",
        "'''!pip install ultralytics\n",
        "!pip install supervision[assets]\n",
        "!yolo settings sync=False\n",
        "\n",
        "from IPython import display\n",
        "display.clear_output()'''"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MKL5JJz10Q7E"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from ultralytics import YOLO\n",
        "from collections import defaultdict\n",
        "from typing import Tuple, List, Dict, Set\n",
        "import supervision as sv\n",
        "import numpy as np\n",
        "import time\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vZbciYyj3_SX",
        "outputId": "c3e9edb2-dc55-44d4-ee4a-6d2b2a98b3f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.3.0/yolov8s.pt to 'yolov8s.pt'...\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 21.5M/21.5M [00:00<00:00, 424MB/s]\n"
          ]
        }
      ],
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "model = YOLO(\"yolov8s.pt\").to(device)\n",
        "\n",
        "\n",
        "vehicle_ids = [1, 2, 3, 4, 5, 6, 7, 8]\n",
        "vehicle_classes = ['bicycle', 'car', 'motorcycle', 'airplane', 'bus', 'train', 'truck', 'boat']\n",
        "id_to_label = dict(zip(vehicle_ids, vehicle_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "edU1z14q6Rri"
      },
      "outputs": [],
      "source": [
        "def crop_detections_to_roi(a, b):\n",
        "  pass\n",
        "def draw_roi_on_frame(a, b):\n",
        "  pass\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vil83uDt3Ny0"
      },
      "outputs": [],
      "source": [
        "def analyze_vehicle_flow(model, vehicle_ids,\n",
        "                         input_video_path: str, sample_frames: int = 200) -> Tuple[sv.Point, sv.Point, str]:\n",
        "    \"\"\"\n",
        "    Analyze vehicle movement pattern to determine optimal counting line placement.\n",
        "\n",
        "    Args:\n",
        "        model: YOLO model instance for vehicle detection\n",
        "        vehicle_ids: List of class IDs for vehicle types to detect\n",
        "        input_video_path (str): Path to input video file\n",
        "        sample_frames (int): Number of frames to analyze. Defaults to 100.\n",
        "\n",
        "    Returns:\n",
        "        Tuple[sv.Point, sv.Point, str]: Start point, end point, and orientation\n",
        "        (\"horizontal\" or \"vertical\") of the optimal counting line.\n",
        "    \"\"\"\n",
        "    generator = sv.get_video_frames_generator(input_video_path)\n",
        "\n",
        "    frame = next(iter(generator))\n",
        "    height, width, _ = frame.shape\n",
        "\n",
        "    # Tracking for traffic flow analysis\n",
        "    byte_tracker = sv.ByteTrack(\n",
        "        track_activation_threshold=0.25,\n",
        "        lost_track_buffer=30,\n",
        "        minimum_matching_threshold=0.8,\n",
        "        frame_rate=30,\n",
        "        minimum_consecutive_frames=3\n",
        "    )\n",
        "\n",
        "    trajectories = defaultdict(list)\n",
        "    frame_count = 0\n",
        "\n",
        "    for frame in generator:\n",
        "        if frame_count >= sample_frames:\n",
        "            break\n",
        "\n",
        "        results = model(frame, verbose=False)[0]\n",
        "        detections = sv.Detections.from_ultralytics(results)\n",
        "        detections = detections[np.isin(detections.class_id, vehicle_ids)]\n",
        "\n",
        "        detections = byte_tracker.update_with_detections(detections)\n",
        "\n",
        "        # Use centroids to track -> less affected by minor variations than bbox\n",
        "        for i, tracker_id in enumerate(detections.tracker_id):\n",
        "            if tracker_id is not None:\n",
        "                bbox = detections.xyxy[i]\n",
        "                centroid = ((bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2)\n",
        "                trajectories[tracker_id].append(centroid)\n",
        "\n",
        "        frame_count += 1\n",
        "\n",
        "    horizontal_movements = []\n",
        "    vertical_movements = []\n",
        "\n",
        "    for track_id, points in trajectories.items():\n",
        "        if len(points) >= 5:  # Minimum points for reliable direction (Gave it 5 hard coded)\n",
        "            start_point = points[0]\n",
        "            end_point = points[-1]\n",
        "\n",
        "            dx = end_point[0] - start_point[0]  # horizontal displacement\n",
        "            dy = end_point[1] - start_point[1]  # vertical displacement\n",
        "\n",
        "            horizontal_movements.append(abs(dx))\n",
        "            vertical_movements.append(abs(dy))\n",
        "\n",
        "    # If the traffic flow cannot be found in given frames (200), then our default is a horizontal line in the center\n",
        "    # (This decision was made by considering the test video \"highway.ts\")\n",
        "    if not horizontal_movements and not vertical_movements:\n",
        "        return (sv.Point(0, height // 2), sv.Point(width, height // 2), \"horizontal\")   # center horizontal line\n",
        "\n",
        "    avg_horizontal = np.mean(horizontal_movements) if horizontal_movements else 0\n",
        "    avg_vertical = np.mean(vertical_movements) if vertical_movements else 0\n",
        "\n",
        "    if avg_horizontal > avg_vertical:   # Dominant horizontal movement -> vertical counting line\n",
        "        x_pos = int(width * 0.5)\n",
        "        return (sv.Point(x_pos, 0), sv.Point(x_pos, height), \"vertical\")\n",
        "    else:\n",
        "        y_pos = int(height * 0.5)   # Dominant vertical movement -> horizontal counting line\n",
        "        return (sv.Point(0, y_pos), sv.Point(width, y_pos), \"horizontal\")\n",
        "\n",
        "def create_multiple_counting_lines(width: int, height: int, direction: str, num_lines: int = 3) -> List[sv.LineZone]:\n",
        "    \"\"\"\n",
        "    Create multiple counting lines that divide the video into equal segments.\n",
        "\n",
        "    Args:\n",
        "        width (int): Video frame width in pixels\n",
        "        height (int): Video frame height in pixels\n",
        "        direction (str): Line orientation, either \"horizontal\" or \"vertical\"\n",
        "        num_lines (int): Number of counting lines to create. Defaults to 3.\n",
        "\n",
        "    Returns:\n",
        "        List[sv.LineZone]: List of LineZone objects representing the counting lines.\n",
        "        Creates (num_lines + 1) equal segments across the frame.\n",
        "    \"\"\"\n",
        "    lines = []\n",
        "    # For n lines -> (n+1) equal segments\n",
        "    # Single line -> at center\n",
        "    if num_lines == 1:\n",
        "\n",
        "        if direction == \"horizontal\":\n",
        "            y_pos = int(height * 0.5)\n",
        "            lines.append(sv.LineZone(start=sv.Point(0, y_pos), end=sv.Point(width, y_pos)))\n",
        "        else:\n",
        "            x_pos = int(width * 0.5)\n",
        "            lines.append(sv.LineZone(start=sv.Point(x_pos, 0), end=sv.Point(x_pos, height)))\n",
        "\n",
        "    # num_lines lines that equally far away from each other\n",
        "    else:\n",
        "\n",
        "        if direction == \"horizontal\":\n",
        "            segment_height = height / (num_lines + 1)\n",
        "            for i in range(num_lines):\n",
        "                y_pos = int(segment_height * (i + 1))\n",
        "                lines.append(sv.LineZone(start=sv.Point(0, y_pos), end=sv.Point(width, y_pos)))\n",
        "        else:\n",
        "            segment_width = width / (num_lines + 1)\n",
        "            for i in range(num_lines):\n",
        "                x_pos = int(segment_width * (i + 1))\n",
        "                lines.append(sv.LineZone(start=sv.Point(x_pos, 0), end=sv.Point(x_pos, height)))\n",
        "\n",
        "    return lines\n",
        "\n",
        "class LineCrossingTracker:\n",
        "    \"\"\"\n",
        "    Tracker class that identifies which specific vehicles cross which lines.\n",
        "    \"\"\"\n",
        "    def __init__(self, num_lines: int):\n",
        "        self.num_lines = num_lines\n",
        "        self.vehicle_line_positions = {}  # vehicle positions relative to each line -> {tracker_id: {line_id: \"side\"}}\n",
        "        self.crossed_vehicles = defaultdict(set)  # which vehicles have crossed which lines -> {tracker_id: {(line_id, direction)}}\n",
        "        self.line_crossings = {}  # {line_id: {\"in\": [(tracker_id, class_name)], \"out\": [...]}}\n",
        "\n",
        "        for line_id in range(num_lines):\n",
        "            self.line_crossings[line_id] = {\"in\": [], \"out\": []}\n",
        "\n",
        "    def get_vehicle_side_of_line(self, centroid: Tuple[float, float], line_zone: sv.LineZone, direction: str) -> str:\n",
        "        \"\"\"\n",
        "        Determine which side of the line a vehicle is on.\n",
        "\n",
        "        Args:\n",
        "            centroid (Tuple[float, float]): Vehicle center coordinates (x, y)\n",
        "            line_zone (sv.LineZone): Line zone object to check against\n",
        "            direction (str): Line orientation (\"horizontal\" or \"vertical\")\n",
        "\n",
        "        Returns:\n",
        "            str: Side identifier (\"top\"/\"bottom\" for horizontal, \"left\"/\"right\" for vertical)\n",
        "        \"\"\"\n",
        "        x, y = centroid\n",
        "\n",
        "        if direction == \"horizontal\":\n",
        "            # For horizontal lines, compare y coordinates\n",
        "            line_y = line_zone.vector.start.y\n",
        "            return \"top\" if y < line_y else \"bottom\"\n",
        "        else:\n",
        "            # For vertical lines, compare x coordinates\n",
        "            line_x = line_zone.vector.start.x\n",
        "            return \"left\" if x < line_x else \"right\"\n",
        "\n",
        "    def update_vehicle_positions(self, detections: sv.Detections, counting_lines: List[sv.LineZone], direction: str, class_names: dict) -> List[Tuple[int, int, str, str]]:\n",
        "        \"\"\"\n",
        "        Update vehicle positions and detect line crossings.\n",
        "\n",
        "        Args:\n",
        "            detections (sv.Detections): Current frame detections with tracking IDs\n",
        "            counting_lines (List[sv.LineZone]): List of counting line zones\n",
        "            direction (str): Line orientation (\"horizontal\" or \"vertical\")\n",
        "            class_names (dict): Mapping of class IDs to class names\n",
        "\n",
        "        Returns:\n",
        "            List[Tuple[int, int, str, str]]: List of (tracker_id, line_id, direction, class_name)\n",
        "            for newly crossed vehicles\n",
        "        \"\"\"\n",
        "        newly_crossed = []\n",
        "\n",
        "        for i, tracker_id in enumerate(detections.tracker_id):\n",
        "            if tracker_id is None:\n",
        "                continue\n",
        "\n",
        "            class_id = detections.class_id[i]\n",
        "            class_name = class_names[class_id]\n",
        "            bbox = detections.xyxy[i]\n",
        "            centroid = ((bbox[0] + bbox[2]) / 2, (bbox[1] + bbox[3]) / 2)\n",
        "\n",
        "            if tracker_id not in self.vehicle_line_positions:\n",
        "                self.vehicle_line_positions[tracker_id] = {}\n",
        "\n",
        "            # position relative to each line\n",
        "            for line_id, line_zone in enumerate(counting_lines):\n",
        "                current_side = self.get_vehicle_side_of_line(centroid, line_zone, direction)\n",
        "\n",
        "                if line_id in self.vehicle_line_positions[tracker_id]:\n",
        "                    previous_side = self.vehicle_line_positions[tracker_id][line_id]    # previous position for this vehicle on this line\n",
        "\n",
        "                    if previous_side != current_side:   # Vehicle crossed the line\n",
        "                        if direction == \"horizontal\":\n",
        "                            crossing_direction = \"in\" if (previous_side == \"bottom\" and current_side == \"top\") else \"out\"\n",
        "                        else:\n",
        "                            crossing_direction = \"in\" if (previous_side == \"left\" and current_side == \"right\") else \"out\"\n",
        "\n",
        "                        crossing_key = (line_id, crossing_direction)\n",
        "                        # Save the crossing if not recorded -> prevent duplication\n",
        "                        if crossing_key not in self.crossed_vehicles[tracker_id]:\n",
        "                            self.crossed_vehicles[tracker_id].add(crossing_key)\n",
        "                            self.line_crossings[line_id][crossing_direction].append((tracker_id, class_name))\n",
        "                            newly_crossed.append((tracker_id, line_id, crossing_direction, class_name))\n",
        "\n",
        "                self.vehicle_line_positions[tracker_id][line_id] = current_side\n",
        "\n",
        "        return newly_crossed\n",
        "\n",
        "    def get_unique_vehicle_count(self) -> int:\n",
        "        \"\"\"\n",
        "        Get count of unique vehicles that have crossed any line.\n",
        "\n",
        "        Returns:\n",
        "            int: Number of unique vehicles that have crossed at least one line\n",
        "        \"\"\"\n",
        "        return len(self.crossed_vehicles)\n",
        "\n",
        "    def get_line_stats(self, line_id: int) -> Dict:\n",
        "        \"\"\"\n",
        "        Get statistics for a specific line.\n",
        "\n",
        "        Args:\n",
        "            line_id (int): ID of the line to get stats for\n",
        "\n",
        "        Returns:\n",
        "            Dict: Statistics containing in_count, out_count, in_vehicles, out_vehicles\n",
        "        \"\"\"\n",
        "        if line_id in self.line_crossings:\n",
        "            return {\n",
        "                \"in_count\": len(self.line_crossings[line_id][\"in\"]),\n",
        "                \"out_count\": len(self.line_crossings[line_id][\"out\"]),\n",
        "                \"in_vehicles\": self.line_crossings[line_id][\"in\"],\n",
        "                \"out_vehicles\": self.line_crossings[line_id][\"out\"]\n",
        "            }\n",
        "        return {\"in_count\": 0, \"out_count\": 0, \"in_vehicles\": [], \"out_vehicles\": []}\n",
        "\n",
        "def count_vehicles_multiline(model, vehicle_ids,\n",
        "                             input_video_path, output_video_path, stats_output_path,\n",
        "                             roi_coords, frame_skip=0,\n",
        "                             num_lines=3) -> int:\n",
        "    \"\"\"\n",
        "    Count vehicles crossing multiple counting lines with tracking.\n",
        "\n",
        "    Args:\n",
        "        model: YOLO model instance for vehicle detection\n",
        "        vehicle_ids: List of class IDs for vehicle types to detect\n",
        "        input_video_path (str): Path to input video file\n",
        "        output_video_path (str): Path to save annotated output video\n",
        "        stats_output_path (str): Path to save counting statistics\n",
        "        num_lines (int): Number of counting lines to create. Defaults to 3.\n",
        "\n",
        "    Returns:\n",
        "        int: Total number of unique vehicles that crossed any line\n",
        "    \"\"\"\n",
        "\n",
        "    output_dir = os.path.dirname(output_video_path)\n",
        "    if output_dir and not os.path.exists(output_dir):\n",
        "        os.makedirs(output_dir)\n",
        "\n",
        "    stats_dir = os.path.dirname(stats_output_path)\n",
        "    if stats_dir and not os.path.exists(stats_dir):\n",
        "        os.makedirs(stats_dir)\n",
        "\n",
        "    frame_times = []\n",
        "\n",
        "    generator = sv.get_video_frames_generator(input_video_path)\n",
        "\n",
        "    frame = next(iter(generator))\n",
        "    height, width, _ = frame.shape\n",
        "\n",
        "    # Adaptive sizing based on video dimensions for aesthetic appearance\n",
        "    base_size = min(width, height)\n",
        "    line_thickness = max(2, int(base_size / 400))\n",
        "    line_text_thickness = max(1, int(base_size / 600))\n",
        "    line_text_scale = max(0.5, base_size / 1200)\n",
        "    box_thickness = max(1, int(base_size / 500))\n",
        "    label_text_thickness = max(1, int(base_size / 800))\n",
        "    label_text_scale = max(0.4, base_size / 1500)\n",
        "\n",
        "    # vehicle flow patterns\n",
        "    line_start, line_end, direction = analyze_vehicle_flow(model=model, vehicle_ids=vehicle_ids, input_video_path=input_video_path)\n",
        "\n",
        "    if roi_coords:\n",
        "        x_min, y_min, x_max, y_max = roi_coords\n",
        "        roi_width = x_max - x_min\n",
        "        roi_height = y_max - y_min\n",
        "        print(f\"Using ROI: ({x_min}, {y_min}) to ({x_max}, {y_max})\")\n",
        "\n",
        "        # Create counting lines within ROI\n",
        "        counting_lines = create_multiple_counting_lines(roi_width, roi_height, direction, num_lines)\n",
        "        # Adjust line coordinates to ROI offset\n",
        "        for line in counting_lines:\n",
        "            line.vector.start.x += x_min\n",
        "            line.vector.start.y += y_min\n",
        "            line.vector.end.x += x_min\n",
        "            line.vector.end.y += y_min\n",
        "    else:\n",
        "        roi_width, roi_height = width, height\n",
        "        counting_lines = create_multiple_counting_lines(width, height, direction, num_lines)\n",
        "        print(\"Processing entire frame\")\n",
        "\n",
        "    crossing_tracker = LineCrossingTracker(num_lines)\n",
        "\n",
        "    # Annotators for each line\n",
        "    line_annotators = []\n",
        "    for i, line in enumerate(counting_lines):\n",
        "        if direction == \"horizontal\":\n",
        "            custom_in = f\"Line {i+1}: Bottom to Top\"\n",
        "            custom_out = f\"Line {i+1}: Top to Bottom\"\n",
        "        else:\n",
        "            custom_in = f\"Line {i+1}: Left to Right\"\n",
        "            custom_out = f\"Line {i+1}: Right to Left\"\n",
        "\n",
        "        annotator = sv.LineZoneAnnotator(\n",
        "            thickness=line_thickness,\n",
        "            text_thickness=line_text_thickness,\n",
        "            text_scale=line_text_scale,\n",
        "            custom_in_text=custom_in,\n",
        "            custom_out_text=custom_out\n",
        "        )\n",
        "        line_annotators.append(annotator)\n",
        "\n",
        "    # Tracker\n",
        "    byte_tracker = sv.ByteTrack(\n",
        "        track_activation_threshold=0.25,\n",
        "        lost_track_buffer=30,\n",
        "        minimum_matching_threshold=0.8,\n",
        "        frame_rate=30,\n",
        "        minimum_consecutive_frames=3\n",
        "    )\n",
        "\n",
        "    # Reset generator for main processing\n",
        "    generator = sv.get_video_frames_generator(input_video_path)\n",
        "\n",
        "    # Annotators with adaptive sizing\n",
        "    box_annotator = sv.BoxAnnotator(thickness=box_thickness)\n",
        "    label_annotator = sv.LabelAnnotator(\n",
        "        text_thickness=label_text_thickness,\n",
        "        text_scale=label_text_scale,\n",
        "        text_color=sv.Color.BLACK\n",
        "    )\n",
        "\n",
        "    frame_skip = frame_skip # If other than 0, then process the frames by skipping\n",
        "    def callback(frame: np.ndarray, index: int) -> np.ndarray:\n",
        "        \"\"\"\n",
        "        Process each video frame for vehicle detection and counting.\n",
        "\n",
        "        Args:\n",
        "            frame (np.ndarray): Current video frame\n",
        "            index (int): Frame index in the video sequence\n",
        "\n",
        "        Returns:\n",
        "            np.ndarray: Annotated frame with detections, tracking, and counting lines\n",
        "        \"\"\"\n",
        "\n",
        "        if index % (frame_skip+1) != 0:\n",
        "            return frame\n",
        "        start_time = time.time()\n",
        "\n",
        "        # model prediction\n",
        "        results = model(frame, verbose=False)[0]\n",
        "        detections = sv.Detections.from_ultralytics(results)\n",
        "        detections = detections[np.isin(detections.class_id, vehicle_ids)]\n",
        "\n",
        "        if roi_coords:\n",
        "            detections = crop_detections_to_roi(detections, roi_coords)\n",
        "\n",
        "        detections = byte_tracker.update_with_detections(detections)\n",
        "        crossing_tracker.update_vehicle_positions(\n",
        "            detections, counting_lines, direction, model.model.names\n",
        "        )\n",
        "        labels = [\n",
        "            f\"#{model.model.names[class_id].capitalize()} {tracker_id}\" # e.g #Car 5\n",
        "            for class_id, tracker_id in zip(detections.class_id, detections.tracker_id)\n",
        "        ]\n",
        "\n",
        "        # Annotate frame\n",
        "        annotated_frame = frame.copy()\n",
        "        if roi_coords:\n",
        "            annotated_frame = draw_roi_on_frame(annotated_frame, roi_coords)\n",
        "        annotated_frame = box_annotator.annotate(scene=annotated_frame, detections=detections)\n",
        "        annotated_frame = label_annotator.annotate(scene=annotated_frame, detections=detections, labels=labels)\n",
        "\n",
        "        # Update line counters for visualization (this is separate from tracking)\n",
        "        for line in counting_lines:\n",
        "            line.trigger(detections)\n",
        "        for line, annotator in zip(counting_lines, line_annotators):\n",
        "            annotated_frame = annotator.annotate(annotated_frame, line_counter=line)\n",
        "\n",
        "        end_time = time.time()\n",
        "        frame_times.append((end_time - start_time) * 1000)  # will be used to calculate average frame processing time\n",
        "\n",
        "        return annotated_frame\n",
        "\n",
        "    # Process video\n",
        "    sv.process_video(\n",
        "        source_path=input_video_path,\n",
        "        target_path=output_video_path,\n",
        "        callback=callback\n",
        "    )\n",
        "\n",
        "    # CALCULATE STATS\n",
        "    unique_vehicle_count = crossing_tracker.get_unique_vehicle_count()\n",
        "\n",
        "    # Calculate totals from tracker (not the line counters)\n",
        "    total_in = sum(crossing_tracker.get_line_stats(i)[\"in_count\"] for i in range(num_lines))\n",
        "    total_out = sum(crossing_tracker.get_line_stats(i)[\"out_count\"] for i in range(num_lines))\n",
        "\n",
        "    avg_frame_time = sum(frame_times) / len(frame_times) if frame_times else 0\n",
        "\n",
        "    total_frames = len(frame_times) * (frame_skip + 1)\n",
        "    total_processing_time = sum(frame_times)\n",
        "    avg_effective_time_per_frame = total_processing_time / total_frames if total_frames > 0 else 0\n",
        "\n",
        "    with open(stats_output_path, \"w\") as f:\n",
        "        if roi_coords:\n",
        "            f.write(f\"ROI coordinates: ({roi_coords[0]}, {roi_coords[1]}) to ({roi_coords[2]}, {roi_coords[3]})\\n\")\n",
        "        f.write(f\"Number of counting lines: {num_lines}\\n\")\n",
        "        f.write(f\"Total unique vehicles that crossed lines: {unique_vehicle_count}\\n\")\n",
        "        f.write(f\"Total crossings: IN={total_in}, OUT={total_out}\\n\")\n",
        "        f.write(f\"Average frame processing time: {avg_frame_time:.2f} ms\\n\")\n",
        "        f.write(f\"Number of frames skipped: {frame_skip}\\n\")\n",
        "        f.write(f\"Average effective time per video frame: {avg_effective_time_per_frame:.2f} ms\\n\")\n",
        "\n",
        "\n",
        "        for i in range(num_lines):\n",
        "            line_stats = crossing_tracker.get_line_stats(i)\n",
        "            f.write(f\"\\nLine {i+1}:\\n\")\n",
        "            f.write(f\"  Total: IN={line_stats['in_count']}, OUT={line_stats['out_count']}\\n\")\n",
        "\n",
        "            if line_stats['in_vehicles']:\n",
        "                f.write(f\"  Vehicles going IN: \")\n",
        "                vehicle_list = [f\"{class_name} #{tracker_id}\" for tracker_id, class_name in line_stats['in_vehicles']]\n",
        "                f.write(\", \".join(vehicle_list) + \"\\n\")\n",
        "\n",
        "            if line_stats['out_vehicles']:\n",
        "                f.write(f\"  Vehicles going OUT: \")\n",
        "                vehicle_list = [f\"{class_name} #{tracker_id}\" for tracker_id, class_name in line_stats['out_vehicles']]\n",
        "                f.write(\", \".join(vehicle_list) + \"\\n\")\n",
        "\n",
        "    return unique_vehicle_count"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDO_s1EI268a",
        "outputId": "9f827bba-9739-43dc-c5f1-7bcc9ab066dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing entire frame\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vehicles_multiline(\n",
        "        model=model, vehicle_ids=vehicle_ids,\n",
        "        input_video_path=\"/content/highway.ts\",\n",
        "        output_video_path=\"/content/result_highway_skip0_3lines_gpu.mp4\",\n",
        "        stats_output_path=\"/content/output_highway_skip0_3lines_gpu.txt\",\n",
        "        num_lines=3,\n",
        "        frame_skip=0,\n",
        "        roi_coords = None\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rljPpG0W3odp",
        "outputId": "2cace61e-f274-4b6c-f03b-4fd1c421867d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Processing entire frame\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "execution_count": 12,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "count_vehicles_multiline(\n",
        "        model=model, vehicle_ids=vehicle_ids,\n",
        "        input_video_path=\"/content/highway.ts\",\n",
        "        output_video_path=\"/content/result_highway_skip2_3lines_gpu.mp4\",\n",
        "        stats_output_path=\"/content/output_highway_skip2_3lines_gpu.txt\",\n",
        "        num_lines=3,\n",
        "        frame_skip=2,\n",
        "        roi_coords = None\n",
        "    )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MQbJydAr-Ik5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
